# Use the official NVIDIA CUDA base image. The -devel tag is crucial as it includes
# the full CUDA toolkit with the nvcc compiler, which is required for JIT compiling
# the custom kernels. We match the version used in the project's Modal examples
# for consistency.
FROM nvidia/cuda:12.9.0-devel-ubuntu24.04

# Set environment variables to prevent interactive prompts during build
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# # Install system dependencies: Python 3.10, pip, git for version control,
# # and g++/ninja for C++/CUDA compilation via PyTorch extensions.
# RUN apt-get update && \
#     apt-get install -y --no-install-recommends \
#     python3.10 \
#     python3-pip \
#     git \
#     g++ \
#     ninja-build && \
#     rm -rf /var/lib/apt/lists/*

# Set a working directory inside the container
WORKDIR /app

# Copy the requirements file first to leverage Docker layer caching.
# This layer will only be rebuilt if the requirements change.
COPY requirements.txt .

# Install the Python dependencies specified in the project.
RUN pip3 install --no-cache-dir -r requirements.txt

# Copy the entire KernelBench project context into the container's working directory.
# This includes the `src`, `scripts`, and our new `kernelbench_agent` directories.
COPY materials/ .

# Run the editable install for the `src` package, as per the project's setup
# instructions. This makes `from src import ...` work correctly inside the container.
# RUN pip3 install --no-cache-dir -e .

# The default command to run when the container starts.
# We use `sleep infinity` because the `art` framework and `inspect-ai`
# will start this container in the background and then use `docker exec`
# to run commands inside it. This keeps the container alive indefinitely.
CMD ["sleep", "infinity"]